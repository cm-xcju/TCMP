# Real-time Emotion Pre-Recognition in Conversations with Contrastive Multi-modal Dialogue Pre-training
 Thanks for your stay in this repo.
 This project aims to pre-recognize the real-time emotion in multimodal conversation [paper](https://dl.acm.org/doi/10.1145/3583780.3615024)

# ğŸ” Motivation
The objective is to predict the emotion of a forthcoming target
utterance that is highly likely to occur. We believe that this task can
enhance the dialogue systemâ€™s understanding of the interlocutorâ€™s
state of mind, enabling it to prepare an appropriate response in
advance.

# âš™ï¸ Installation
Make sure the following dependencies are intalled.
- python
- pytorch
- Numpy
- tqdm
- json
- argparse
- GTX

## ğŸ’¾ dataset
- dataset 1
- 2
- 3

## ğŸš€ Quick start
There are [] steps for training.
- First,
- Second,
- Third,
- Finally,

### Download 


### step 2


## ğŸ Experiment 


## ğŸ“œCitation

## ğŸ¤˜Furthermore

if your have any quesions, you can just propose the confusion in issue window. We are honored to disscuss the problem with you!

Thanks~
